#!/usr/bin/env python3
"""
æ¨¡å‹ç¯å¢ƒè®¾ç½®è„šæœ¬
å¿«é€Ÿä¸‹è½½å’Œé…ç½®æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹
"""
import asyncio
import logging
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from app.services.models.model_manager import model_manager
from app.services.models.pretrained_models import download_required_models
from app.services.models.custom_models import train_all_models_with_sample_data

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def setup_all_models():
    """è®¾ç½®æ‰€æœ‰æ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®¾ç½®åé¦ˆåˆ†æç³»ç»Ÿæ¨¡å‹...")
    
    try:
        # 1. æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
        print("\nğŸ“‹ æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
        check_system_requirements()
        
        # 2. åˆ›å»ºæ¨¡å‹ç›®å½•
        print("\nğŸ“ åˆ›å»ºæ¨¡å‹ç›®å½•...")
        create_model_directories()
        
        # 3. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
        print("\nâ¬‡ï¸ ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹...")
        await download_pretrained_models()
        
        # 4. è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹ï¼ˆä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼‰
        print("\nğŸ”¨ è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹...")
        await train_custom_models()
        
        # 5. éªŒè¯æ¨¡å‹è®¾ç½®
        print("\nâœ… éªŒè¯æ¨¡å‹è®¾ç½®...")
        await verify_model_setup()
        
        print("\nğŸ‰ æ¨¡å‹è®¾ç½®å®Œæˆï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
        
    except Exception as e:
        logger.error(f"æ¨¡å‹è®¾ç½®å¤±è´¥: {e}")
        print(f"\nâŒ æ¨¡å‹è®¾ç½®å¤±è´¥: {e}")
        sys.exit(1)

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    import torch
    import transformers
    import sklearn
    
    print(f"âœ“ Python: {sys.version}")
    print(f"âœ“ PyTorch: {torch.__version__}")
    print(f"âœ“ Transformers: {transformers.__version__}")
    print(f"âœ“ Scikit-learn: {sklearn.__version__}")
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸ GPU: æœªæ£€æµ‹åˆ°CUDAï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    import shutil
    free_space = shutil.disk_usage('.').free // (1024 * 1024 * 1024)  # GB
    print(f"âœ“ å¯ç”¨ç£ç›˜ç©ºé—´: {free_space}GB")
    
    if free_space < 2:
        print("âš ï¸ è­¦å‘Šï¼šç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®è‡³å°‘æœ‰2GBå¯ç”¨ç©ºé—´")

def create_model_directories():
    """åˆ›å»ºæ¨¡å‹ç›®å½•"""
    directories = [
        "models",
        "models/pretrained",
        "models/pretrained/transformers",
        "models/pretrained/sentence_transformers", 
        "models/custom",
        "models/logs"
    ]
    
    for dir_path in directories:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"âœ“ åˆ›å»ºç›®å½•: {dir_path}")

async def download_pretrained_models():
    """ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹"""
    try:
        # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ç®¡ç†å™¨
        manager = await download_required_models()
        
        info = manager.get_model_info()
        loaded_count = info['loaded_models']
        total_count = info['total_models']
        
        print(f"âœ“ é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å®Œæˆ: {loaded_count}/{total_count}")
        
        # æ˜¾ç¤ºæ¨¡å‹è¯¦æƒ…
        for name, model_info in info['models'].items():
            status = "âœ…" if model_info['loaded'] else "âŒ"
            print(f"  {status} {name}: {model_info['description']}")
        
    except Exception as e:
        logger.error(f"é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        raise

async def train_custom_models():
    """è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹"""
    try:
        # ä½¿ç”¨ç¤ºä¾‹æ•°æ®è®­ç»ƒ
        results = await train_all_models_with_sample_data()
        
        print("âœ“ è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒå®Œæˆ:")
        
        for model_name, result in results.items():
            if result.success:
                print(f"  âœ… {model_name}: å‡†ç¡®ç‡ {result.accuracy:.3f}")
            else:
                print(f"  âŒ {model_name}: {result.error_message}")
        
    except Exception as e:
        logger.error(f"è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        raise

async def verify_model_setup():
    """éªŒè¯æ¨¡å‹è®¾ç½®"""
    try:
        # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        results = await model_manager.initialize_all_models()
        
        success_count = sum(results.values())
        total_count = len(results)
        
        print(f"âœ“ æ¨¡å‹éªŒè¯å®Œæˆ: {success_count}/{total_count}")
        
        # è·å–è¯¦ç»†ä¿¡æ¯
        info = model_manager.get_model_info()
        
        print("\nğŸ“Š æ¨¡å‹çŠ¶æ€è¯¦æƒ…:")
        print(f"  - é¢„è®­ç»ƒæ¨¡å‹: {info['pretrained_models']['loaded_models']}/{info['pretrained_models']['total_models']}")
        print(f"  - è‡ªå®šä¹‰æ¨¡å‹: {info['custom_models']['loaded_models']}/{info['custom_models']['total_models']}")
        print(f"  - æ¨¡å‹ç›®å½•: {info['model_dir']}")
        
        if success_count == total_count:
            print("ğŸ¯ æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        else:
            print("âš ï¸ éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½†ç³»ç»Ÿä»å¯è¿è¡Œ")
        
    except Exception as e:
        logger.error(f"æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        raise

def print_usage():
    """æ‰“å°ä½¿ç”¨è¯´æ˜"""
    print("""
ğŸ¤– åé¦ˆåˆ†æç³»ç»Ÿ - æ¨¡å‹è®¾ç½®å·¥å…·

ç”¨æ³•:
    python setup_models.py [é€‰é¡¹]

é€‰é¡¹:
    --help          æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
    --check-only    ä»…æ£€æŸ¥ç³»ç»Ÿè¦æ±‚ï¼Œä¸ä¸‹è½½æ¨¡å‹
    --download-only ä»…ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
    --train-only    ä»…è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹

ç¤ºä¾‹:
    # å®Œæ•´è®¾ç½®ï¼ˆæ¨èï¼‰
    python setup_models.py
    
    # ä»…æ£€æŸ¥ç³»ç»Ÿ
    python setup_models.py --check-only
    
    # ä»…ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
    python setup_models.py --download-only

æ³¨æ„:
    - é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½çº¦1GBçš„æ¨¡å‹æ–‡ä»¶
    - å»ºè®®åœ¨è‰¯å¥½çš„ç½‘ç»œç¯å¢ƒä¸‹è¿è¡Œ
    - å¦‚æœ‰GPUï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨GPUåŠ é€Ÿ
    """)

async def main():
    """ä¸»å‡½æ•°"""
    args = sys.argv[1:]
    
    if "--help" in args:
        print_usage()
        return
    
    if "--check-only" in args:
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
        check_system_requirements()
        return
    
    if "--download-only" in args:
        print("â¬‡ï¸ ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹...")
        create_model_directories()
        await download_pretrained_models()
        return
    
    if "--train-only" in args:
        print("ğŸ”¨ è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹...")
        create_model_directories()
        await train_custom_models()
        return
    
    # é»˜è®¤ï¼šå®Œæ•´è®¾ç½®
    await setup_all_models()

if __name__ == "__main__":
    asyncio.run(main()) 
"""
LLMæ´å¯Ÿç”Ÿæˆå™¨
ä½¿ç”¨LLMç›´æ¥ä»ç”¨æˆ·åé¦ˆæ•°æ®ä¸­ç”Ÿæˆæ´å¯Ÿå’Œæ‰§è¡Œè®¡åˆ’
"""
import json
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime
import openai
from ...models.settings import LLMSettings
import re

logger = logging.getLogger(__name__)

@dataclass
class InsightResult:
    """æ´å¯Ÿç»“æœ"""
    insight_id: str
    title: str
    description: str
    insight_type: str              # trend/pattern/opportunity/risk
    confidence_score: float        # 0-1
    impact_level: str              # high/medium/low
    supporting_evidence: List[str] # æ”¯æ’‘è¯æ®
    affected_user_segments: List[str] # å½±å“çš„ç”¨æˆ·ç¾¤ä½“
    business_impact: str           # ä¸šåŠ¡å½±å“æè¿°
    generated_at: datetime
    is_full_text: bool = False     # æ˜¯å¦ä¸ºå…¨æ–‡æ´å¯Ÿ

@dataclass
class ActionPlan:
    """æ‰§è¡Œè®¡åˆ’"""
    plan_id: str
    title: str
    summary: str
    priority: str                  # P0/P1/P2/P3
    estimated_effort: str          # å·¥ä½œé‡ä¼°ç®—
    timeline: str                  # æ—¶é—´çº¿
    owner_team: str                # è´Ÿè´£å›¢é˜Ÿ
    success_metrics: List[str]     # æˆåŠŸæŒ‡æ ‡
    action_steps: List[Dict]       # æ‰§è¡Œæ­¥éª¤
    risk_assessment: str           # é£é™©è¯„ä¼°
    expected_outcome: str          # é¢„æœŸç»“æœ
    related_insights: List[str]    # ç›¸å…³æ´å¯Ÿ
    generated_at: datetime

class LLMInsightGenerator:
    """LLMæ´å¯Ÿç”Ÿæˆå™¨"""
    
    def __init__(self, llm_settings: LLMSettings):
        self.llm_settings = llm_settings
        
        # ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„LLMè®¾ç½®
        if llm_settings.enabled:
            # ä¼˜å…ˆä½¿ç”¨theturboé…ç½®
            api_key = llm_settings.theturbo_api_key if llm_settings.theturbo_api_key else llm_settings.apiKey
            base_url = llm_settings.theturbo_base_url if llm_settings.theturbo_base_url else llm_settings.base_url
            
            self.openai_client = openai.OpenAI(
                api_key=api_key,
                base_url=base_url
            )
            
            logger.info(f"LLMæ´å¯Ÿç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {llm_settings.model}")
        else:
            logger.warning("LLMåŠŸèƒ½å·²ç¦ç”¨ï¼Œå°†æ— æ³•ç”Ÿæˆæ´å¯Ÿ")
            self.openai_client = None

        # å…¨æ–‡æ´å¯Ÿç”Ÿæˆæç¤ºè¯æ¨¡æ¿ï¼ˆåŸºäºæ‰€æœ‰å†å²æ•°æ®ï¼‰
        self.full_text_insight_prompt_template = """
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„äº§å“æˆ˜ç•¥åˆ†æå¸ˆå’Œæ•°æ®æ´å¯Ÿä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹æ‰€æœ‰å†å²ç”¨æˆ·åé¦ˆæ•°æ®ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„å¼ºå¤§åˆ†æèƒ½åŠ›è¿›è¡Œæ·±åº¦å…¨æ–‡åˆ†æï¼Œç”Ÿæˆå…·æœ‰æˆ˜ç•¥ä»·å€¼çš„æ´å¯ŸæŠ¥å‘Šã€‚

ğŸ“Š **å®Œæ•´å†å²åé¦ˆæ•°æ®é›†**ï¼š
{full_feedback_data}

ğŸ“ˆ **æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ**ï¼š
- æ€»åé¦ˆæ•°ï¼š{total_count}
- æ—¶é—´è·¨åº¦ï¼š{time_range}
- æ•°æ®æ¥æºï¼š{data_sources}
- æƒ…æ„Ÿåˆ†å¸ƒï¼š{sentiment_stats}
- ç±»åˆ«åˆ†å¸ƒï¼š{category_stats}
- ä¼˜å…ˆçº§åˆ†å¸ƒï¼š{priority_stats}

ğŸ¯ **å…¨æ–‡æ´å¯Ÿåˆ†æè¦æ±‚**ï¼š
è¯·å¯¹æ‰€æœ‰å†å²åé¦ˆæ•°æ®è¿›è¡Œæ·±åº¦å…¨æ–‡åˆ†æï¼Œç”Ÿæˆå…·æœ‰æˆ˜ç•¥ä»·å€¼çš„æ´å¯Ÿã€‚é‡ç‚¹å…³æ³¨ï¼š

1. **å…¨å±€è¶‹åŠ¿æ´å¯Ÿ**ï¼šè·¨æ—¶é—´ã€è·¨ç±»åˆ«çš„æ•´ä½“è¶‹åŠ¿å’Œå˜åŒ–æ¨¡å¼
2. **æ·±å±‚æ¨¡å¼è¯†åˆ«**ï¼šç”¨æˆ·è¡Œä¸ºæ¨¡å¼ã€é—®é¢˜å…³è”æ€§ã€éšè—éœ€æ±‚
3. **æœºä¼šæŒ–æ˜**ï¼šåŸºäºç”¨æˆ·åé¦ˆå‘ç°çš„äº§å“æœºä¼šå’Œåˆ›æ–°æ–¹å‘
4. **é£é™©é¢„è­¦**ï¼šæ½œåœ¨çš„äº§å“é£é™©ã€ç”¨æˆ·æµå¤±é£é™©å’Œç«äº‰å¨èƒ
5. **ç”¨æˆ·æ´å¯Ÿ**ï¼šä¸åŒç”¨æˆ·ç¾¤ä½“çš„æ·±åº¦éœ€æ±‚åˆ†æå’Œç”¨æˆ·ç”»åƒ
6. **ä¸šåŠ¡å½±å“è¯„ä¼°**ï¼šå¯¹ä¸šåŠ¡ç›®æ ‡ã€æ”¶å…¥ã€ç”¨æˆ·æ»¡æ„åº¦çš„å…·ä½“å½±å“
7. **é•¿æœŸæˆ˜ç•¥æ´å¯Ÿ**ï¼šåŸºäºå†å²æ•°æ®çš„é•¿æœŸå‘å±•è¶‹åŠ¿å’Œæˆ˜ç•¥æ–¹å‘

ğŸ” **æ´å¯Ÿè¦æ±‚**ï¼š
- **ä¸é™åˆ¶ç”Ÿæˆæ´å¯Ÿçš„æ¡æ•°**ï¼Œæ ¹æ®æ•°æ®çš„ä¸°å¯Œç¨‹åº¦å’Œä»·å€¼ï¼Œä»å„ä¸ªè§’åº¦è¿›è¡Œæ·±åº¦åˆ†æ
- æ¯ä¸ªæ´å¯Ÿéœ€è¦æœ‰å……åˆ†çš„æ•°æ®æ”¯æ’‘
- ä¼˜å…ˆç”Ÿæˆé«˜ä»·å€¼ã€å¯æ‰§è¡Œçš„æ´å¯Ÿ
- æ´å¯Ÿè¦å…·æœ‰å‰ç»æ€§å’Œæˆ˜ç•¥æ„ä¹‰
- è¦åŒ…å«å…·ä½“çš„æ•°æ®å¼•ç”¨å’Œè¯æ®
- **æ´å¯Ÿæè¿°å¿…é¡»ä½¿ç”¨markdownæ ¼å¼ï¼ŒåŒ…å«æ ‡é¢˜ã€åˆ—è¡¨ã€é‡ç‚¹æ ‡è®°ã€ä»£ç å—ç­‰ç»“æ„åŒ–å†…å®¹**
- åˆ©ç”¨å…¨é‡æ•°æ®çš„ä¼˜åŠ¿ï¼ŒæŒ–æ˜å•ç‹¬æœˆåº¦åˆ†ææ— æ³•å‘ç°çš„æ·±å±‚æ´å¯Ÿ

ğŸ’¡ **å…¨æ–‡æ´å¯Ÿç‰¹è‰²**ï¼š
- åŸºäºå®Œæ•´å†å²æ•°æ®çš„é•¿æœŸè¶‹åŠ¿åˆ†æ
- è·¨æ—¶é—´ç»´åº¦çš„ç”¨æˆ·è¡Œä¸ºæ¼”å˜æ´å¯Ÿ
- æ·±åº¦å…³è”åˆ†æå’Œæ¨¡å¼è¯†åˆ«
- å‰ç»æ€§æˆ˜ç•¥å»ºè®®å’Œé£é™©é¢„è­¦
- å…¨é‡æ•°æ®æ”¯æ’‘çš„é‡åŒ–æ´å¯Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š
{{
  "insights": [
    {{
      "title": "æ´å¯Ÿæ ‡é¢˜",
      "description": "è¯¦ç»†æè¿°ï¼ˆä½¿ç”¨markdownæ ¼å¼ï¼ŒåŒ…å«## æ ‡é¢˜ã€- åˆ—è¡¨ã€**é‡ç‚¹**ç­‰ç»“æ„åŒ–å†…å®¹ï¼‰",
      "insight_type": "trend/pattern/opportunity/risk",
      "confidence_score": 0.95,
      "impact_level": "high/medium/low",
      "supporting_evidence": ["å…·ä½“è¯æ®1", "å…·ä½“è¯æ®2", "æ•°æ®å¼•ç”¨"],
      "affected_user_segments": ["ç”¨æˆ·ç¾¤ä½“1", "ç”¨æˆ·ç¾¤ä½“2"],
      "business_impact": "å¯¹ä¸šåŠ¡çš„å…·ä½“å½±å“å’Œå»ºè®®",
      "data_references": ["å¼•ç”¨çš„å…·ä½“åé¦ˆIDæˆ–å†…å®¹ç‰‡æ®µ"],
      "strategic_value": "æˆ˜ç•¥ä»·å€¼å’Œæ„ä¹‰"
    }}
  ],
  "executive_summary": {{
    "key_findings": ["å…³é”®å‘ç°1", "å…³é”®å‘ç°2"],
    "top_priorities": ["ä¼˜å…ˆäº‹é¡¹1", "ä¼˜å…ˆäº‹é¡¹2"],
    "strategic_recommendations": ["æˆ˜ç•¥å»ºè®®1", "æˆ˜ç•¥å»ºè®®2"],
    "risk_alerts": ["é£é™©è­¦æŠ¥1", "é£é™©è­¦æŠ¥2"]
  }}
}}
"""

        # æ´å¯Ÿç”Ÿæˆæç¤ºè¯æ¨¡æ¿ï¼ˆåŸºäºæœ€è¿‘ä¸€ä¸ªæœˆæ•°æ®ï¼‰
        self.insight_prompt_template = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç»ç†å’Œæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹æœ€è¿‘ä¸€ä¸ªæœˆçš„ç”¨æˆ·åé¦ˆæ•°æ®ï¼Œç”Ÿæˆæ·±åº¦æ´å¯Ÿå’Œå…·ä½“å¯æ‰§è¡Œçš„æ”¹è¿›å»ºè®®ã€‚

ğŸ“Š **æœ€è¿‘ä¸€ä¸ªæœˆåé¦ˆæ•°æ®æ±‡æ€»**ï¼š
{feedback_summary}

ğŸ“ˆ **åé¦ˆç»Ÿè®¡ä¿¡æ¯**ï¼š
- æ€»åé¦ˆæ•°ï¼š{total_feedback}
- é«˜ä¼˜å…ˆçº§åé¦ˆï¼š{high_priority_count}
- ä¸»è¦æƒ…æ„Ÿåˆ†å¸ƒï¼š{sentiment_distribution}
- ä¸»è¦ç±»åˆ«åˆ†å¸ƒï¼š{category_distribution}
- å…³é”®é—®é¢˜TOP5ï¼š{top_issues}

ğŸ¯ **å¸¸è§„æ´å¯Ÿåˆ†æè¦æ±‚**ï¼š
è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œæ·±åº¦åˆ†æå¹¶ç”Ÿæˆæ´å¯Ÿï¼š

1. **è¶‹åŠ¿æ´å¯Ÿ**ï¼šè¯†åˆ«ç”¨æˆ·åé¦ˆä¸­çš„è¶‹åŠ¿å˜åŒ–å’Œæ¨¡å¼
2. **æœºä¼šæ´å¯Ÿ**ï¼šå‘ç°äº§å“æ”¹è¿›å’Œåˆ›æ–°çš„æœºä¼šç‚¹
3. **é£é™©æ´å¯Ÿ**ï¼šè¯†åˆ«æ½œåœ¨çš„äº§å“é£é™©å’Œç”¨æˆ·æµå¤±é£é™©
4. **ç”¨æˆ·æ´å¯Ÿ**ï¼šåˆ†æä¸åŒç”¨æˆ·ç¾¤ä½“çš„éœ€æ±‚å’Œç—›ç‚¹

ğŸ’¡ **æ´å¯Ÿè¦æ±‚**ï¼š
å¯¹äºæ¯ä¸ªæ´å¯Ÿï¼Œè¯·åŒ…å«ï¼š
- æ´å¯Ÿæ ‡é¢˜ï¼ˆç®€æ´æ˜äº†ï¼‰
- è¯¦ç»†æè¿°ï¼ˆ**ä¸¥æ ¼é™åˆ¶åœ¨300å­—ä»¥å†…**ï¼Œ**å¿…é¡»ä½¿ç”¨markdownæ ¼å¼**ï¼ŒåŒ…å«## æ ‡é¢˜ã€- åˆ—è¡¨ã€**é‡ç‚¹**ç­‰ç»“æ„åŒ–å†…å®¹ï¼‰
- æ´å¯Ÿç±»å‹ï¼ˆtrend/pattern/opportunity/riskï¼‰
- ç½®ä¿¡åº¦ï¼ˆ0-1ï¼ŒåŸºäºæ•°æ®æ”¯æ’‘ç¨‹åº¦ï¼‰
- å½±å“çº§åˆ«ï¼ˆhigh/medium/lowï¼‰
- æ”¯æ’‘è¯æ®ï¼ˆå…·ä½“çš„æ•°æ®ç‚¹æˆ–åé¦ˆå†…å®¹ï¼‰
- å½±å“çš„ç”¨æˆ·ç¾¤ä½“
- ä¸šåŠ¡å½±å“æè¿°ï¼ˆ**å¿…é¡»åŒ…å«å…·ä½“å¯æ‰§è¡Œçš„å»ºè®®ï¼Œè€Œéæ–¹å‘æ€§å»ºè®®**ï¼‰

**é‡è¦æç¤º**ï¼š
- æ¯ä¸ªæ´å¯Ÿçš„ä¸šåŠ¡å½±å“æè¿°å¿…é¡»åŒ…å«å…·ä½“çš„æ‰§è¡Œå»ºè®®ï¼Œä¾‹å¦‚"**ç«‹å³ä¼˜åŒ–**XXåŠŸèƒ½çš„YYé—®é¢˜ï¼Œé¢„è®¡2å‘¨å†…å®Œæˆ"è€Œé"éœ€è¦æ”¹å–„XXåŠŸèƒ½"
- æ´å¯Ÿæè¿°å¿…é¡»åŒ…å«å…·ä½“çš„æ•°æ®æ”¯æ’‘å’Œé‡åŒ–æŒ‡æ ‡
- é¿å…ç©ºæ³›çš„æ–¹å‘æ€§å»ºè®®ï¼Œè¦æ±‚å…·ä½“çš„è¡ŒåŠ¨æ–¹æ¡ˆ
- æè¿°å†…å®¹å¿…é¡»æ§åˆ¶åœ¨300å­—ä»¥å†…ï¼Œä¿æŒç®€æ´ç²¾å‡†

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š
{{
  "insights": [
    {{
      "title": "æ´å¯Ÿæ ‡é¢˜",
      "description": "è¯¦ç»†æè¿°ï¼ˆ**markdownæ ¼å¼ï¼Œä¸¥æ ¼é™åˆ¶300å­—ä»¥å†…**ï¼‰",
      "insight_type": "trend/pattern/opportunity/risk",
      "confidence_score": 0.85,
      "impact_level": "high/medium/low",
      "supporting_evidence": ["è¯æ®1", "è¯æ®2"],
      "affected_user_segments": ["æ–°ç”¨æˆ·", "ä¼ä¸šç”¨æˆ·"],
      "business_impact": "ä¸šåŠ¡å½±å“æè¿°ï¼ˆ**åŒ…å«å…·ä½“å¯æ‰§è¡Œçš„å»ºè®®**ï¼‰"
    }}
  ]
}}
"""

        # æ‰§è¡Œè®¡åˆ’ç”Ÿæˆæç¤ºè¯æ¨¡æ¿
        self.action_plan_prompt_template = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„äº§å“ç»ç†ã€‚åŸºäºä»¥ä¸‹æ´å¯Ÿç»“æœï¼Œåˆ¶å®šå…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚

æ´å¯Ÿç»“æœï¼š
{insights}

ç”¨æˆ·åé¦ˆä¸Šä¸‹æ–‡ï¼š
{context}

è¯·ä¸ºæ¯ä¸ªæ´å¯Ÿåˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼ŒåŒ…å«ï¼š

1. **è®¡åˆ’æ ‡é¢˜**ï¼šç®€æ´æ˜äº†çš„æ‰§è¡Œè®¡åˆ’åç§°
2. **è®¡åˆ’æ¦‚è¦**ï¼š50-100å­—çš„ç®€è¦è¯´æ˜
3. **ä¼˜å…ˆçº§**ï¼šP0(ç´§æ€¥)/P1(é«˜)/P2(ä¸­)/P3(ä½)
4. **é¢„ä¼°å·¥ä½œé‡**ï¼šå¦‚"2-3å‘¨"ã€"1ä¸ªæœˆ"ç­‰
5. **å»ºè®®æ—¶é—´çº¿**ï¼šä½•æ—¶å¼€å§‹å’Œå®Œæˆ
6. **è´Ÿè´£å›¢é˜Ÿ**ï¼šengineering/product/design/marketing
7. **æˆåŠŸæŒ‡æ ‡**ï¼šå¦‚ä½•è¡¡é‡æˆåŠŸ
8. **å…·ä½“æ­¥éª¤**ï¼š3-5ä¸ªå¯æ‰§è¡Œçš„æ­¥éª¤
9. **é£é™©è¯„ä¼°**ï¼šæ½œåœ¨é£é™©å’Œç¼“è§£æªæ–½
10. **é¢„æœŸç»“æœ**ï¼šå®æ–½åçš„é¢„æœŸæ•ˆæœ

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
  "action_plans": [
    {{
      "title": "è®¡åˆ’æ ‡é¢˜",
      "summary": "è®¡åˆ’æ¦‚è¦",
      "priority": "P0/P1/P2/P3",
      "estimated_effort": "å·¥ä½œé‡ä¼°ç®—",
      "timeline": "æ—¶é—´çº¿",
      "owner_team": "è´Ÿè´£å›¢é˜Ÿ",
      "success_metrics": ["æŒ‡æ ‡1", "æŒ‡æ ‡2"],
      "action_steps": [
        {{"step": 1, "description": "æ­¥éª¤æè¿°", "owner": "è´Ÿè´£äºº", "duration": "æ—¶é•¿"}},
        {{"step": 2, "description": "æ­¥éª¤æè¿°", "owner": "è´Ÿè´£äºº", "duration": "æ—¶é•¿"}}
      ],
      "risk_assessment": "é£é™©è¯„ä¼°",
      "expected_outcome": "é¢„æœŸç»“æœ",
      "related_insights": ["ç›¸å…³æ´å¯Ÿæ ‡é¢˜"]
    }}
  ]
}}
"""
    
    async def generate_full_text_insights(self, feedback_data: List[Dict]) -> Dict:
        """
        å…¨æ–‡æ´å¯Ÿç”Ÿæˆ - åˆ©ç”¨geminiçš„1Mä¸Šä¸‹æ–‡èƒ½åŠ›ä¸€æ¬¡æ€§åˆ†ææ‰€æœ‰åé¦ˆæ•°æ®
        """
        try:
            logger.info(f"å¼€å§‹å…¨æ–‡æ´å¯Ÿåˆ†æï¼Œæ•°æ®é‡: {len(feedback_data)}æ¡")
            
            # å‡†å¤‡å®Œæ•´çš„åé¦ˆæ•°æ®
            full_data = self._prepare_full_feedback_data(feedback_data)
            
            # æ„å»ºå…¨æ–‡æ´å¯Ÿæç¤ºè¯
            prompt = self.full_text_insight_prompt_template.format(**full_data)
            
            # è°ƒç”¨LLMç”Ÿæˆå…¨æ–‡æ´å¯Ÿ
            response = await self._call_llm(prompt)
            
            # è§£æå…¨æ–‡æ´å¯Ÿç»“æœ
            result = self._parse_full_text_insights_response(response)
            
            logger.info(f"å…¨æ–‡æ´å¯Ÿåˆ†æå®Œæˆï¼Œç”Ÿæˆ{len(result.get('insights', []))}ä¸ªæ´å¯Ÿ")
            return result
            
        except Exception as e:
            logger.error(f"å…¨æ–‡æ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            return {"insights": [], "executive_summary": {}}
    
    async def generate_insights_from_feedback(self, feedback_data: List[Dict]) -> List[InsightResult]:
        """ä»åé¦ˆæ•°æ®ç”Ÿæˆæ´å¯Ÿ"""
        try:
            # å‡†å¤‡æ•°æ®æ‘˜è¦
            summary = self._prepare_feedback_summary(feedback_data)
            
            # æ„å»ºæç¤ºè¯
            prompt = self.insight_prompt_template.format(**summary)
            
            # è°ƒç”¨LLMç”Ÿæˆæ´å¯Ÿ
            response = await self._call_llm(prompt)
            
            # è§£æç»“æœ
            insights = self._parse_insights_response(response)
            
            logger.info(f"æˆåŠŸç”Ÿæˆ{len(insights)}ä¸ªæ´å¯Ÿ")
            return insights
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ´å¯Ÿå¤±è´¥: {e}")
            return []
    
    async def generate_action_plans_from_insights(self, insights: List[InsightResult], feedback_context: Dict) -> List[ActionPlan]:
        """ä»æ´å¯Ÿç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        try:
            # å‡†å¤‡æ´å¯Ÿæ•°æ®
            insights_data = [
                {
                    "title": insight.title,
                    "description": insight.description,
                    "insight_type": insight.insight_type,
                    "impact_level": insight.impact_level,
                    "confidence_score": insight.confidence_score
                }
                for insight in insights
            ]
            
            # æ„å»ºæç¤ºè¯
            prompt = self.action_plan_prompt_template.format(
                insights=json.dumps(insights_data, ensure_ascii=False, indent=2),
                context=json.dumps(feedback_context, ensure_ascii=False, indent=2)
            )
            
            # è°ƒç”¨LLMç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            response = await self._call_llm(prompt)
            
            # è§£æç»“æœ
            action_plans = self._parse_action_plans_response(response)
            
            logger.info(f"æˆåŠŸç”Ÿæˆ{len(action_plans)}ä¸ªæ‰§è¡Œè®¡åˆ’")
            return action_plans
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‰§è¡Œè®¡åˆ’å¤±è´¥: {e}")
            return []
    
    def _prepare_feedback_summary(self, feedback_data: List[Dict]) -> Dict:
        """å‡†å¤‡åé¦ˆæ•°æ®æ‘˜è¦"""
        total_feedback = len(feedback_data)
        
        # ç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
        sentiment_counts = {}
        category_counts = {}
        high_priority_count = 0
        
        sample_feedback = []
        
        for feedback in feedback_data:
            # æƒ…æ„Ÿç»Ÿè®¡
            sentiment = feedback.get('filter_result', {}).get('sentiment', 'neutral')
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
            
            # ç±»åˆ«ç»Ÿè®¡
            category = feedback.get('filter_result', {}).get('category', 'general')
            category_counts[category] = category_counts.get(category, 0) + 1
            
            # é«˜ä¼˜å…ˆçº§ç»Ÿè®¡
            priority_score = feedback.get('filter_result', {}).get('priority_score', 0)
            if priority_score > 0.7:
                high_priority_count += 1
            
            # æ”¶é›†æ ·æœ¬åé¦ˆ
            if len(sample_feedback) < 10:
                sample_feedback.append({
                    "text": feedback.get('text', '')[:200],
                    "sentiment": sentiment,
                    "category": category,
                    "priority_score": priority_score
                })
        
        # è¯†åˆ«TOPé—®é¢˜
        top_issues = self._identify_top_issues(feedback_data)
        
        return {
            "feedback_summary": json.dumps(sample_feedback, ensure_ascii=False, indent=2),
            "total_feedback": total_feedback,
            "high_priority_count": high_priority_count,
            "sentiment_distribution": sentiment_counts,
            "category_distribution": category_counts,
            "top_issues": top_issues
        }
    
    def _prepare_full_feedback_data(self, feedback_data: List[Dict]) -> Dict:
        """å‡†å¤‡å®Œæ•´çš„åé¦ˆæ•°æ®ç”¨äºå…¨æ–‡æ´å¯Ÿ"""
        all_feedback_text = "".join([f"ç”¨æˆ·åé¦ˆ: {f.get('text', '')}\n" for f in feedback_data])
        total_count = len(feedback_data)
        time_range = "N/A" # éœ€è¦ä»åé¦ˆæ•°æ®ä¸­æå–
        data_sources = "ç”¨æˆ·ç›´æ¥åé¦ˆ" # éœ€è¦ä»åé¦ˆæ•°æ®ä¸­æå–
        
        sentiment_stats = {}
        category_stats = {}
        priority_stats = {}
        
        for f in feedback_data:
            sentiment = f.get('filter_result', {}).get('sentiment', 'neutral')
            sentiment_stats[sentiment] = sentiment_stats.get(sentiment, 0) + 1
            
            category = f.get('filter_result', {}).get('category', 'general')
            category_stats[category] = category_stats.get(category, 0) + 1
            
            priority_score = f.get('filter_result', {}).get('priority_score', 0)
            priority_level = "high" if priority_score > 0.7 else "medium" if priority_score > 0.3 else "low"
            priority_stats[priority_level] = priority_stats.get(priority_level, 0) + 1
        
        return {
            "full_feedback_data": all_feedback_text,
            "total_count": total_count,
            "time_range": time_range,
            "data_sources": data_sources,
            "sentiment_stats": sentiment_stats,
            "category_stats": category_stats,
            "priority_stats": priority_stats
        }
    
    def _parse_full_text_insights_response(self, response: str) -> Dict:
        """è§£æå…¨æ–‡æ´å¯Ÿå“åº”"""
        try:
            logger.info(f"åŸå§‹å…¨æ–‡æ´å¯Ÿå“åº”: {response[:500]}...")
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            response = response.strip()
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()
            elif '```' in response:
                start = response.find('```') + 3
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()
            
            if '{' in response:
                start = response.find('{')
                end = response.rfind('}') + 1
                if end > start:
                    response = response[start:end]
            
            logger.info(f"æ¸…ç†åçš„å…¨æ–‡æ´å¯ŸJSON: {response[:200]}...")
            
            # å°è¯•ä¿®å¤JSONæ ¼å¼é—®é¢˜
            response = self._fix_json_format(response)
            
            data = json.loads(response)
            
            # è§£ææ´å¯Ÿåˆ—è¡¨
            insights = []
            for i, insight_data in enumerate(data.get('insights', [])):
                insight = InsightResult(
                    insight_id=f"full_text_insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i}",
                    title=insight_data.get('title', ''),
                    description=insight_data.get('description', ''),
                    insight_type=insight_data.get('insight_type', 'pattern'),
                    confidence_score=insight_data.get('confidence_score', 0.5),
                    impact_level=insight_data.get('impact_level', 'medium'),
                    supporting_evidence=insight_data.get('supporting_evidence', []),
                    affected_user_segments=insight_data.get('affected_user_segments', []),
                    business_impact=insight_data.get('business_impact', ''),
                    generated_at=datetime.now(),
                    is_full_text=True  # æ ‡è®°ä¸ºå…¨æ–‡æ´å¯Ÿ
                )
                insights.append(insight)
            
            # è§£ææ‰§è¡Œæ‘˜è¦
            executive_summary = {
                "key_findings": data.get('executive_summary', {}).get('key_findings', []),
                "top_priorities": data.get('executive_summary', {}).get('top_priorities', []),
                "strategic_recommendations": data.get('executive_summary', {}).get('strategic_recommendations', []),
                "risk_alerts": data.get('executive_summary', {}).get('risk_alerts', [])
            }
            
            return {"insights": insights, "executive_summary": executive_summary}
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£æå…¨æ–‡æ´å¯Ÿå“åº”å¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return {"insights": [], "executive_summary": {}}
        except Exception as e:
            logger.error(f"å¤„ç†å…¨æ–‡æ´å¯Ÿå“åº”æ—¶å‡ºé”™: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return {"insights": [], "executive_summary": {}}
    
    def _fix_json_format(self, json_str: str) -> str:
        """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
        try:
            # ç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦
            json_str = json_str.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
            
            # å‹ç¼©å¤šä½™çš„ç©ºæ ¼
            json_str = re.sub(r'\s+', ' ', json_str)
            
            # ä¿®å¤æˆªæ–­çš„JSON - æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
            if not json_str.strip().endswith('}'):
                logger.info("æ£€æµ‹åˆ°JSONæˆªæ–­ï¼Œå°è¯•ä¿®å¤...")
                
                # è®¡ç®—å¤§æ‹¬å·å¹³è¡¡
                brace_count = 0
                bracket_count = 0
                in_string = False
                escape_next = False
                last_complete_pos = -1
                
                for i, char in enumerate(json_str):
                    if escape_next:
                        escape_next = False
                        continue
                    
                    if char == '\\':
                        escape_next = True
                        continue
                    
                    if char == '"' and not escape_next:
                        in_string = not in_string
                        continue
                    
                    if not in_string:
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                last_complete_pos = i
                        elif char == '[':
                            bracket_count += 1
                        elif char == ']':
                            bracket_count -= 1
                
                # å¦‚æœæ‰¾åˆ°å®Œæ•´çš„å¯¹è±¡ï¼Œæˆªå–åˆ°é‚£ä¸ªä½ç½®
                if last_complete_pos > 0:
                    json_str = json_str[:last_complete_pos + 1]
                    logger.info(f"æˆåŠŸä¿®å¤JSONæˆªæ–­ï¼Œæˆªå–åˆ°ä½ç½®: {last_complete_pos}")
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„å¯¹è±¡ï¼Œå°è¯•æ‰‹åŠ¨è¡¥å…¨
                    logger.info("å°è¯•æ‰‹åŠ¨è¡¥å…¨JSON...")
                    
                    # è®¡ç®—éœ€è¦è¡¥å…¨çš„æ‹¬å·æ•°é‡
                    missing_braces = brace_count
                    missing_brackets = bracket_count
                    
                    # ç§»é™¤æœ«å°¾çš„ä¸å®Œæ•´éƒ¨åˆ†
                    json_str = json_str.rstrip(', \t\n\r')
                    
                    # è¡¥å…¨ç¼ºå¤±çš„æ‹¬å·
                    for _ in range(missing_brackets):
                        json_str += ']'
                    for _ in range(missing_braces):
                        json_str += '}'
                    
                    logger.info(f"è¡¥å…¨äº† {missing_brackets} ä¸ªæ–¹æ‹¬å·å’Œ {missing_braces} ä¸ªå¤§æ‹¬å·")
            
            # ä¿®å¤å¸¸è§çš„JSONè¯­æ³•é”™è¯¯
            # ç§»é™¤å°¾éƒ¨é€—å·
            json_str = re.sub(r',\s*}', '}', json_str)
            json_str = re.sub(r',\s*]', ']', json_str)
            
            # ä¿®å¤å¼•å·é—®é¢˜
            json_str = json_str.replace('""', '"')
            
            # ä¿®å¤æ•°å­—æ ¼å¼é—®é¢˜
            json_str = re.sub(r'(\d+)\.(\d+)', r'\1.\2', json_str)
            
            # éªŒè¯ä¿®å¤åçš„JSON
            try:
                json.loads(json_str)
                logger.info("JSONä¿®å¤æˆåŠŸï¼Œæ ¼å¼éªŒè¯é€šè¿‡")
                return json_str
            except json.JSONDecodeError as e:
                logger.warning(f"JSONä¿®å¤åä»æœ‰æ ¼å¼é—®é¢˜: {e}")
                # å°è¯•æ›´æ¿€è¿›çš„ä¿®å¤
                return self._aggressive_json_fix(json_str)
            
        except Exception as e:
            logger.error(f"ä¿®å¤JSONæ ¼å¼æ—¶å‡ºé”™: {e}")
            return json_str
    
    def _aggressive_json_fix(self, json_str: str) -> str:
        """æ›´æ¿€è¿›çš„JSONä¿®å¤æ–¹æ³•"""
        try:
            logger.info("æ‰§è¡Œæ¿€è¿›çš„JSONä¿®å¤...")
            
            # å°è¯•æå–insightséƒ¨åˆ†
            insights_start = json_str.find('"insights":')
            if insights_start == -1:
                logger.error("æœªæ‰¾åˆ°insightså­—æ®µ")
                return '{"insights": [], "executive_summary": {}}'
            
            # æŸ¥æ‰¾insightsæ•°ç»„çš„å¼€å§‹
            array_start = json_str.find('[', insights_start)
            if array_start == -1:
                logger.error("æœªæ‰¾åˆ°insightsæ•°ç»„")
                return '{"insights": [], "executive_summary": {}}'
            
            # å°è¯•æå–å®Œæ•´çš„insightså¯¹è±¡
            insights_objects = []
            brace_count = 0
            current_object = ""
            in_string = False
            escape_next = False
            
            i = array_start + 1
            while i < len(json_str):
                char = json_str[i]
                
                if escape_next:
                    current_object += char
                    escape_next = False
                    i += 1
                    continue
                
                if char == '\\':
                    escape_next = True
                    current_object += char
                    i += 1
                    continue
                
                if char == '"':
                    in_string = not in_string
                    current_object += char
                    i += 1
                    continue
                
                if not in_string:
                    if char == '{':
                        brace_count += 1
                        current_object += char
                    elif char == '}':
                        brace_count -= 1
                        current_object += char
                        if brace_count == 0:
                            # æ‰¾åˆ°ä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
                            try:
                                obj = json.loads(current_object)
                                insights_objects.append(obj)
                                current_object = ""
                                logger.info(f"æˆåŠŸæå–ç¬¬{len(insights_objects)}ä¸ªæ´å¯Ÿå¯¹è±¡")
                            except json.JSONDecodeError:
                                logger.warning(f"å¯¹è±¡{len(insights_objects)+1}æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                                current_object = ""
                    elif char == ']':
                        break
                    else:
                        current_object += char
                else:
                    current_object += char
                
                i += 1
            
            # æ„å»ºæœ€ç»ˆçš„JSON
            result = {
                "insights": insights_objects,
                "executive_summary": {
                    "key_findings": [],
                    "top_priorities": [],
                    "strategic_recommendations": [],
                    "risk_alerts": []
                }
            }
            
            logger.info(f"æ¿€è¿›ä¿®å¤å®Œæˆï¼Œæå–äº†{len(insights_objects)}ä¸ªæ´å¯Ÿå¯¹è±¡")
            return json.dumps(result, ensure_ascii=False)
            
        except Exception as e:
            logger.error(f"æ¿€è¿›JSONä¿®å¤å¤±è´¥: {e}")
            return '{"insights": [], "executive_summary": {}}'
    
    def _identify_top_issues(self, feedback_data: List[Dict]) -> List[str]:
        """è¯†åˆ«TOPé—®é¢˜"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºå…³é”®è¯é¢‘ç‡
        from collections import Counter
        
        all_keywords = []
        for feedback in feedback_data:
            keywords = feedback.get('filter_result', {}).get('extracted_keywords', [])
            all_keywords.extend(keywords)
        
        if all_keywords:
            top_keywords = Counter(all_keywords).most_common(5)
            return [f"{keyword}({count}æ¬¡æåŠ)" for keyword, count in top_keywords]
        
        return ["æš‚æ— æ˜æ˜¾é—®é¢˜æ¨¡å¼"]
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM"""
        try:
            if not self.openai_client:
                raise Exception("LLMåŠŸèƒ½å·²ç¦ç”¨")
                
            response = self.openai_client.chat.completions.create(
                model=self.llm_settings.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç»ç†å’Œæ•°æ®åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.llm_settings.temperature,
                max_tokens=self.llm_settings.maxTokens
            )
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"è°ƒç”¨LLMå¤±è´¥: {e}")
            raise
    
    def _parse_insights_response(self, response: str) -> List[InsightResult]:
        """è§£ææ´å¯Ÿå“åº”"""
        try:
            logger.info(f"åŸå§‹LLMå“åº”: {response[:500]}...")  # è®°å½•å‰500å­—ç¬¦
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            response = response.strip()
            if '```json' in response:
                # æå–JSONä»£ç å—
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()
            elif '```' in response:
                # æå–ä»»ä½•ä»£ç å—
                start = response.find('```') + 3
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()
            
            # å¦‚æœå“åº”ä»¥{å¼€å¤´ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            if '{' in response:
                start = response.find('{')
                # æ‰¾åˆ°æœ€åä¸€ä¸ª}
                end = response.rfind('}') + 1
                if end > start:
                    response = response[start:end]
            
            logger.info(f"æ¸…ç†åçš„JSON: {response[:200]}...")
            
            data = json.loads(response)
            insights = []
            
            for i, insight_data in enumerate(data.get('insights', [])):
                insight = InsightResult(
                    insight_id=f"insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i}",
                    title=insight_data.get('title', ''),
                    description=insight_data.get('description', ''),
                    insight_type=insight_data.get('insight_type', 'pattern'),
                    confidence_score=insight_data.get('confidence_score', 0.5),
                    impact_level=insight_data.get('impact_level', 'medium'),
                    supporting_evidence=insight_data.get('supporting_evidence', []),
                    affected_user_segments=insight_data.get('affected_user_segments', []),
                    business_impact=insight_data.get('business_impact', ''),
                    generated_at=datetime.now()
                )
                insights.append(insight)
            
            return insights
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£ææ´å¯Ÿå“åº”å¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return []
        except Exception as e:
            logger.error(f"å¤„ç†æ´å¯Ÿå“åº”æ—¶å‡ºé”™: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return []
    
    def _parse_action_plans_response(self, response: str) -> List[ActionPlan]:
        """è§£ææ‰§è¡Œè®¡åˆ’å“åº”"""
        try:
            logger.info(f"åŸå§‹æ‰§è¡Œè®¡åˆ’å“åº”: {response[:500]}...")
            
            # åŒæ ·çš„JSONæ¸…ç†é€»è¾‘
            response = response.strip()
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()
            elif '```' in response:
                start = response.find('```') + 3
                end = response.find('```', start)
                if end != -1:
                    response = response[start:end].strip()
            
            if '{' in response:
                start = response.find('{')
                end = response.rfind('}') + 1
                if end > start:
                    response = response[start:end]
            
            logger.info(f"æ¸…ç†åçš„æ‰§è¡Œè®¡åˆ’JSON: {response[:200]}...")
            
            data = json.loads(response)
            action_plans = []
            
            for i, plan_data in enumerate(data.get('action_plans', [])):
                plan = ActionPlan(
                    plan_id=f"plan_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{i}",
                    title=plan_data.get('title', ''),
                    summary=plan_data.get('summary', ''),
                    priority=plan_data.get('priority', 'P2'),
                    estimated_effort=plan_data.get('estimated_effort', ''),
                    timeline=plan_data.get('timeline', ''),
                    owner_team=plan_data.get('owner_team', 'product'),
                    success_metrics=plan_data.get('success_metrics', []),
                    action_steps=plan_data.get('action_steps', []),
                    risk_assessment=plan_data.get('risk_assessment', ''),
                    expected_outcome=plan_data.get('expected_outcome', ''),
                    related_insights=plan_data.get('related_insights', []),
                    generated_at=datetime.now()
                )
                action_plans.append(plan)
            
            return action_plans
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£ææ‰§è¡Œè®¡åˆ’å“åº”å¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return []
        except Exception as e:
            logger.error(f"å¤„ç†æ‰§è¡Œè®¡åˆ’å“åº”æ—¶å‡ºé”™: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return []

# å…¨å±€å®ä¾‹
llm_insight_generator = None

def get_llm_insight_generator(llm_settings: LLMSettings) -> LLMInsightGenerator:
    """è·å–LLMæ´å¯Ÿç”Ÿæˆå™¨å®ä¾‹"""
    global llm_insight_generator
    
    if llm_insight_generator is None:
        llm_insight_generator = LLMInsightGenerator(llm_settings)
    
    return llm_insight_generator 
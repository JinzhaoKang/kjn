"""
æ•°æ®æºé€‚é…å™¨ç³»ç»Ÿ
è´Ÿè´£å°†ä¸åŒå¹³å°çš„åŸå§‹æ•°æ®è½¬æ¢ä¸ºç»Ÿä¸€çš„æ•°æ®æ ¼å¼
"""
import logging
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Dict, List, Optional, Any, Type
from dataclasses import dataclass

from ...models.data_source import (
    FeedbackData, DataSourceType, ContentType, UserInfo, 
    ProductInfo, PlatformMetadata, MediaAttachment, ProcessingStatus
)
from ...models.geographical import (
    GeographicalInfo, CountryCode, RegionCode, LanguageCode,
    get_geographical_manager
)

logger = logging.getLogger(__name__)

@dataclass
class RawDataItem:
    """åŸå§‹æ•°æ®é¡¹"""
    source_type: DataSourceType
    raw_data: Dict[str, Any]
    metadata: Dict[str, Any] = None

class BaseDataAdapter(ABC):
    """æ•°æ®é€‚é…å™¨åŸºç±»"""
    
    def __init__(self, source_type: DataSourceType):
        self.source_type = source_type
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    @abstractmethod
    def can_handle(self, raw_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†æ­¤æ•°æ®"""
        pass
    
    @abstractmethod
    def transform(self, raw_data: Dict[str, Any]) -> FeedbackData:
        """å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        pass
    
    def validate_data(self, data: FeedbackData) -> bool:
        """éªŒè¯è½¬æ¢åçš„æ•°æ®"""
        try:
            # åŸºç¡€å­—æ®µéªŒè¯
            if not data.content or len(data.content.strip()) < 1:
                return False
            
            if not data.original_id:
                return False
            
            if not data.created_at:
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def extract_user_info(self, raw_data: Dict[str, Any]) -> Optional[UserInfo]:
        """æå–ç”¨æˆ·ä¿¡æ¯ï¼ˆå­ç±»å¯é‡å†™ï¼‰"""
        return None
    
    def extract_product_info(self, raw_data: Dict[str, Any]) -> Optional[ProductInfo]:
        """æå–äº§å“ä¿¡æ¯ï¼ˆå­ç±»å¯é‡å†™ï¼‰"""
        return None
    
    def extract_platform_metadata(self, raw_data: Dict[str, Any]) -> Optional[PlatformMetadata]:
        """æå–å¹³å°å…ƒæ•°æ®ï¼ˆå­ç±»å¯é‡å†™ï¼‰"""
        return None
    
    def detect_geographical_info(self, raw_data: Dict[str, Any], content: str = None) -> GeographicalInfo:
        """æ£€æµ‹åœ°ç†ä½ç½®ä¿¡æ¯ ğŸŒ"""
        geo_manager = get_geographical_manager()
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼çš„å›½å®¶ä¿¡æ¯
        explicit_country = None
        if 'country' in raw_data:
            country_str = raw_data['country'].upper()
            try:
                explicit_country = CountryCode(country_str)
            except ValueError:
                pass
        
        # 2. ä»å¹³å°ä¿¡æ¯æ£€æµ‹
        platform_name = None
        if hasattr(self, 'source_type'):
            platform_name = self.source_type.value
        
        # 3. ä»å†…å®¹æ£€æµ‹è¯­è¨€
        text_content = content or raw_data.get('content', raw_data.get('text', ''))
        
        # 4. ä»IPåœ°å€æ£€æµ‹ï¼ˆå¦‚æœæœ‰ï¼‰
        ip_address = raw_data.get('ip_address', raw_data.get('user_ip'))
        
        # ç»¼åˆæ£€æµ‹
        geo_info = geo_manager.get_geographical_info(
            platform_name=platform_name,
            text_content=text_content,
            ip_address=ip_address,
            explicit_country=explicit_country
        )
        
        self.logger.debug(f"æ£€æµ‹åˆ°åœ°ç†ä½ç½®ä¿¡æ¯: {geo_info.country_name} ({geo_info.detection_method})")
        
        return geo_info

class SocialMediaAdapter(BaseDataAdapter):
    """ç¤¾äº¤åª’ä½“é€‚é…å™¨åŸºç±»"""
    
    def extract_user_info(self, raw_data: Dict[str, Any]) -> Optional[UserInfo]:
        """æå–ç¤¾äº¤åª’ä½“ç”¨æˆ·ä¿¡æ¯"""
        user_data = raw_data.get('user', {})
        
        if not user_data:
            return None
        
        return UserInfo(
            user_id=user_data.get('id'),
            username=user_data.get('username'),
            nickname=user_data.get('nickname', user_data.get('display_name')),
            avatar_url=user_data.get('avatar_url'),
            follower_count=user_data.get('follower_count', 0),
            level=user_data.get('level'),
            is_verified=user_data.get('is_verified', False),
            registration_date=self._parse_datetime(user_data.get('registration_date'))
        )
    
    def extract_platform_metadata(self, raw_data: Dict[str, Any]) -> Optional[PlatformMetadata]:
        """æå–ç¤¾äº¤åª’ä½“å¹³å°å…ƒæ•°æ®"""
        return PlatformMetadata(
            post_id=raw_data.get('id'),
            parent_id=raw_data.get('parent_id'),
            thread_id=raw_data.get('thread_id'),
            likes_count=raw_data.get('likes_count', 0),
            comments_count=raw_data.get('comments_count', 0),
            shares_count=raw_data.get('shares_count', 0),
            views_count=raw_data.get('views_count', 0),
            is_pinned=raw_data.get('is_pinned', False),
            is_featured=raw_data.get('is_featured', False),
            tags=raw_data.get('tags', []),
            hashtags=raw_data.get('hashtags', []),
            mentions=raw_data.get('mentions', []),
            location=raw_data.get('location')
        )
    
    def _parse_datetime(self, date_str: Any) -> Optional[datetime]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
        if not date_str:
            return None
        
        if isinstance(date_str, datetime):
            return date_str
        
        try:
            # å¸¸è§çš„æ—¶é—´æ ¼å¼
            formats = [
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%dT%H:%M:%S",
                "%Y-%m-%dT%H:%M:%S.%f",
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y/%m/%d %H:%M:%S"
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(str(date_str), fmt)
                except ValueError:
                    continue
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œå°è¯•pandasè§£æ
            import pandas as pd
            return pd.to_datetime(date_str).to_pydatetime()
            
        except Exception as e:
            self.logger.warning(f"æ—¶é—´è§£æå¤±è´¥: {date_str}, {e}")
            return None

class XiaohongshuAdapter(SocialMediaAdapter):
    """å°çº¢ä¹¦æ•°æ®é€‚é…å™¨"""
    
    def __init__(self):
        super().__init__(DataSourceType.XIAOHONGSHU)
    
    def can_handle(self, raw_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå°çº¢ä¹¦æ•°æ®"""
        return (
            'note_id' in raw_data or 
            'platform' in raw_data and raw_data['platform'] == 'xiaohongshu'
        )
    
    def transform(self, raw_data: Dict[str, Any]) -> FeedbackData:
        """è½¬æ¢å°çº¢ä¹¦æ•°æ®"""
        content = raw_data.get('content', raw_data.get('text', ''))
        
        return FeedbackData(
            source_type=self.source_type,
            source_platform="å°çº¢ä¹¦",
            original_id=raw_data.get('note_id', raw_data.get('id')),
            url=raw_data.get('url'),
            title=raw_data.get('title'),
            content=content,
            content_type=self._determine_content_type(raw_data),
            created_at=self._parse_datetime(raw_data.get('created_time', raw_data.get('publish_time'))),
            published_at=self._parse_datetime(raw_data.get('publish_time')),
            user_info=self.extract_user_info(raw_data),
            platform_metadata=self.extract_platform_metadata(raw_data),
            attachments=self._extract_attachments(raw_data),
            geographical_info=self.detect_geographical_info(raw_data, content),  # ğŸŒ æ–°å¢åœ°ç†ä½ç½®æ£€æµ‹
            processing_status=ProcessingStatus()
        )
    
    def _determine_content_type(self, raw_data: Dict[str, Any]) -> ContentType:
        """åˆ¤æ–­å†…å®¹ç±»å‹"""
        if raw_data.get('images') or raw_data.get('pic_ids'):
            if raw_data.get('video_url'):
                return ContentType.MIXED
            return ContentType.IMAGE
        elif raw_data.get('video_url'):
            return ContentType.VIDEO
        else:
            return ContentType.TEXT
    
    def _extract_attachments(self, raw_data: Dict[str, Any]) -> List[MediaAttachment]:
        """æå–åª’ä½“é™„ä»¶"""
        attachments = []
        
        # å¤„ç†å›¾ç‰‡
        images = raw_data.get('images', [])
        for img in images:
            attachments.append(MediaAttachment(
                type=ContentType.IMAGE,
                url=img.get('url', img) if isinstance(img, dict) else img,
                thumbnail_url=img.get('thumbnail_url') if isinstance(img, dict) else None
            ))
        
        # å¤„ç†è§†é¢‘
        video_url = raw_data.get('video_url')
        if video_url:
            attachments.append(MediaAttachment(
                type=ContentType.VIDEO,
                url=video_url,
                thumbnail_url=raw_data.get('video_cover'),
                duration=raw_data.get('video_duration')
            ))
        
        return attachments

class DouyinAdapter(SocialMediaAdapter):
    """æŠ–éŸ³æ•°æ®é€‚é…å™¨"""
    
    def __init__(self):
        super().__init__(DataSourceType.DOUYIN)
    
    def can_handle(self, raw_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæŠ–éŸ³æ•°æ®"""
        return (
            'aweme_id' in raw_data or
            'platform' in raw_data and raw_data['platform'] == 'douyin'
        )
    
    def transform(self, raw_data: Dict[str, Any]) -> FeedbackData:
        """è½¬æ¢æŠ–éŸ³æ•°æ®"""
        return FeedbackData(
            source_type=self.source_type,
            source_platform="æŠ–éŸ³",
            original_id=raw_data.get('aweme_id', raw_data.get('id')),
            url=raw_data.get('share_url'),
            title=raw_data.get('desc'),  # æŠ–éŸ³é€šå¸¸æ²¡æœ‰æ ‡é¢˜
            content=raw_data.get('desc', ''),
            content_type=ContentType.VIDEO,  # æŠ–éŸ³ä¸»è¦æ˜¯è§†é¢‘å†…å®¹
            created_at=self._parse_datetime(raw_data.get('create_time')),
            user_info=self.extract_user_info(raw_data),
            platform_metadata=self.extract_platform_metadata(raw_data),
            processing_status=ProcessingStatus()
        )

class EcommerceAdapter(BaseDataAdapter):
    """ç”µå•†å¹³å°é€‚é…å™¨åŸºç±»"""
    
    def extract_product_info(self, raw_data: Dict[str, Any]) -> Optional[ProductInfo]:
        """æå–å•†å“ä¿¡æ¯"""
        product_data = raw_data.get('product', {})
        
        return ProductInfo(
            product_id=product_data.get('id', raw_data.get('product_id')),
            product_name=product_data.get('name', raw_data.get('product_name')),
            category=product_data.get('category'),
            brand=product_data.get('brand'),
            version=product_data.get('version'),
            price=product_data.get('price'),
            rating=product_data.get('rating', raw_data.get('product_rating'))
        )

class TaobaoAdapter(EcommerceAdapter):
    """æ·˜å®æ•°æ®é€‚é…å™¨"""
    
    def __init__(self):
        super().__init__(DataSourceType.TAOBAO)
    
    def can_handle(self, raw_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ·˜å®æ•°æ®"""
        return (
            'review_id' in raw_data or
            'platform' in raw_data and raw_data['platform'] == 'taobao'
        )
    
    def transform(self, raw_data: Dict[str, Any]) -> FeedbackData:
        """è½¬æ¢æ·˜å®è¯„è®ºæ•°æ®"""
        return FeedbackData(
            source_type=self.source_type,
            source_platform="æ·˜å®",
            original_id=raw_data.get('review_id', raw_data.get('id')),
            url=raw_data.get('product_url'),
            content=raw_data.get('content', raw_data.get('review_text', '')),
            content_type=ContentType.TEXT,
            created_at=self._parse_datetime(raw_data.get('review_time')),
            user_info=self._extract_taobao_user(raw_data),
            product_info=self.extract_product_info(raw_data),
            platform_metadata=self._extract_taobao_metadata(raw_data),
            processing_status=ProcessingStatus()
        )
    
    def _extract_taobao_user(self, raw_data: Dict[str, Any]) -> Optional[UserInfo]:
        """æå–æ·˜å®ç”¨æˆ·ä¿¡æ¯"""
        return UserInfo(
            user_id=raw_data.get('user_id'),
            username=raw_data.get('username'),
            nickname=raw_data.get('user_nick'),
            level=raw_data.get('user_level'),
            is_verified=raw_data.get('is_vip', False)
        )
    
    def _extract_taobao_metadata(self, raw_data: Dict[str, Any]) -> PlatformMetadata:
        """æå–æ·˜å®å¹³å°å…ƒæ•°æ®"""
        return PlatformMetadata(
            post_id=raw_data.get('review_id'),
            likes_count=raw_data.get('useful_count', 0),
            tags=raw_data.get('tags', [])
        )

class AppStoreAdapter(BaseDataAdapter):
    """åº”ç”¨å•†åº—é€‚é…å™¨åŸºç±»"""
    
    def extract_product_info(self, raw_data: Dict[str, Any]) -> Optional[ProductInfo]:
        """æå–åº”ç”¨ä¿¡æ¯"""
        app_data = raw_data.get('app', {})
        
        return ProductInfo(
            product_id=app_data.get('id', raw_data.get('app_id')),
            product_name=app_data.get('name', raw_data.get('app_name')),
            category=app_data.get('category'),
            brand=app_data.get('developer', raw_data.get('developer')),
            version=app_data.get('version', raw_data.get('app_version')),
            rating=raw_data.get('rating')
        )

class IOSAppStoreAdapter(AppStoreAdapter):
    """iOS App Storeé€‚é…å™¨"""
    
    def __init__(self):
        super().__init__(DataSourceType.APP_STORE)
    
    def can_handle(self, raw_data: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºApp Storeæ•°æ®"""
        return (
            'review_id' in raw_data and 'platform' in raw_data and 
            raw_data['platform'] in ['app_store', 'ios']
        )
    
    def transform(self, raw_data: Dict[str, Any]) -> FeedbackData:
        """è½¬æ¢App Storeè¯„è®ºæ•°æ®"""
        return FeedbackData(
            source_type=self.source_type,
            source_platform="App Store",
            original_id=raw_data.get('review_id', raw_data.get('id')),
            url=raw_data.get('app_url'),
            title=raw_data.get('title'),
            content=raw_data.get('content', raw_data.get('review_text', '')),
            content_type=ContentType.TEXT,
            created_at=self._parse_datetime(raw_data.get('created_date')),
            user_info=self._extract_appstore_user(raw_data),
            product_info=self.extract_product_info(raw_data),
            platform_metadata=self._extract_appstore_metadata(raw_data),
            processing_status=ProcessingStatus()
        )
    
    def _extract_appstore_user(self, raw_data: Dict[str, Any]) -> Optional[UserInfo]:
        """æå–App Storeç”¨æˆ·ä¿¡æ¯"""
        return UserInfo(
            username=raw_data.get('reviewer_name'),
            user_id=raw_data.get('reviewer_id')
        )
    
    def _extract_appstore_metadata(self, raw_data: Dict[str, Any]) -> PlatformMetadata:
        """æå–App Storeå…ƒæ•°æ®"""
        return PlatformMetadata(
            post_id=raw_data.get('review_id'),
            likes_count=raw_data.get('helpfulness_count', 0)
        )

class DataAdapterRegistry:
    """æ•°æ®é€‚é…å™¨æ³¨å†Œè¡¨"""
    
    def __init__(self):
        self.adapters: Dict[DataSourceType, BaseDataAdapter] = {}
        self.logger = logging.getLogger(__name__)
        self._register_default_adapters()
    
    def _register_default_adapters(self):
        """æ³¨å†Œé»˜è®¤é€‚é…å™¨"""
        adapters = [
            XiaohongshuAdapter(),
            DouyinAdapter(),
            TaobaoAdapter(),
            IOSAppStoreAdapter(),
        ]
        
        for adapter in adapters:
            self.register_adapter(adapter)
    
    def register_adapter(self, adapter: BaseDataAdapter):
        """æ³¨å†Œé€‚é…å™¨"""
        self.adapters[adapter.source_type] = adapter
        logger.info(f"æ³¨å†Œæ•°æ®é€‚é…å™¨: {adapter.source_type.value}")
    
    def get_adapter(self, source_type: DataSourceType) -> Optional[BaseDataAdapter]:
        """è·å–é€‚é…å™¨"""
        return self.adapters.get(source_type)
    
    def find_adapter(self, raw_data: Dict[str, Any]) -> Optional[BaseDataAdapter]:
        """æ ¹æ®åŸå§‹æ•°æ®æŸ¥æ‰¾åˆé€‚çš„é€‚é…å™¨"""
        for adapter in self.adapters.values():
            if adapter.can_handle(raw_data):
                return adapter
        return None
    
    def transform_data(self, raw_data: Dict[str, Any], source_type: DataSourceType = None) -> Optional[FeedbackData]:
        """è½¬æ¢å•æ¡åŸå§‹æ•°æ®ä¸ºæ ‡å‡†æ ¼å¼"""
        try:
            # å¦‚æœæŒ‡å®šäº†æºç±»å‹ï¼Œä¼˜å…ˆä½¿ç”¨å¯¹åº”çš„é€‚é…å™¨
            if source_type:
                adapter = self.get_adapter(source_type)
                if adapter and adapter.can_handle(raw_data):
                    feedback_data = adapter.transform(raw_data)
                    if adapter.validate_data(feedback_data):
                        return feedback_data
            
            # è‡ªåŠ¨æŸ¥æ‰¾é€‚é…å™¨
            adapter = self.find_adapter(raw_data)
            if adapter:
                feedback_data = adapter.transform(raw_data)
                if adapter.validate_data(feedback_data):
                    return feedback_data
                else:
                    self.logger.warning(f"æ•°æ®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡æ•°æ®")
                    return None
            else:
                self.logger.warning(f"æœªæ‰¾åˆ°åˆé€‚çš„é€‚é…å™¨å¤„ç†æ•°æ®: {list(raw_data.keys())[:3]}")
                return None
        
        except Exception as e:
            self.logger.error(f"æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            return None

    async def batch_import_data(self, 
                               data: List[Dict[str, Any]], 
                               source_type: str = "spider",
                               metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ‰¹é‡å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“"""
        from ...models.database import UserFeedback, FeedbackSource
        
        imported_count = 0
        failed_count = 0
        failed_items = []
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡å¯¼å…¥ {len(data)} æ¡æ•°æ®")
        
        for i, raw_item in enumerate(data):
            try:
                # åˆ¤æ–­æ•°æ®æºç±»å‹
                if source_type == "spider":
                    # å¤„ç†çˆ¬è™«æ•°æ®
                    feedback_doc = await self._convert_spider_data_to_feedback(raw_item, metadata)
                else:
                    # å¤„ç†å…¶ä»–ç±»å‹æ•°æ®
                    feedback_doc = await self._convert_raw_data_to_feedback(raw_item, source_type, metadata)
                
                if feedback_doc:
                    # ä¿å­˜åˆ°MongoDB
                    await feedback_doc.save()
                    imported_count += 1
                    self.logger.debug(f"æˆåŠŸå¯¼å…¥ç¬¬ {i+1} æ¡æ•°æ®")
                else:
                    failed_count += 1
                    failed_items.append({"index": i, "reason": "æ•°æ®è½¬æ¢å¤±è´¥"})
                    
            except Exception as e:
                failed_count += 1
                failed_items.append({"index": i, "reason": str(e)})
                self.logger.error(f"å¯¼å…¥ç¬¬ {i+1} æ¡æ•°æ®å¤±è´¥: {e}")
        
        self.logger.info(f"æ‰¹é‡å¯¼å…¥å®Œæˆ: æˆåŠŸ {imported_count} æ¡ï¼Œå¤±è´¥ {failed_count} æ¡")
        
        return {
            "imported_count": imported_count,
            "failed_count": failed_count,
            "total_count": len(data),
            "failed_items": failed_items[:10],  # åªè¿”å›å‰10ä¸ªå¤±è´¥é¡¹
            "success_rate": imported_count / len(data) if data else 0
        }
    
    async def _convert_spider_data_to_feedback(self, 
                                             spider_data: Dict[str, Any], 
                                             metadata: Dict[str, Any] = None) -> Optional['UserFeedback']:
        """å°†çˆ¬è™«æ•°æ®è½¬æ¢ä¸ºUserFeedbackæ–‡æ¡£"""
        from ...models.database import UserFeedback, FeedbackSource
        
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            content = spider_data.get('content', spider_data.get('text', ''))
            if not content or len(content.strip()) < 1:
                return None
                
            # åˆ¤æ–­å¹³å°ç±»å‹
            platform = spider_data.get('platform', 'unknown')
            if platform in ['ios', 'app_store']:
                source = FeedbackSource.APP_STORE
            elif platform == 'android':
                source = FeedbackSource.GOOGLE_PLAY
            else:
                source = FeedbackSource.INTERNAL
            
            # è§£ææ—¶é—´
            feedback_time = self._parse_spider_time(spider_data.get('created_at', spider_data.get('date')))
            
            # æ„å»ºå¹³å°å…ƒæ•°æ®
            platform_metadata = {
                "original_id": spider_data.get('id', spider_data.get('review_id')),
                "rating": spider_data.get('rating'),
                "title": spider_data.get('title'),
                "author": spider_data.get('author', spider_data.get('username')),
                "app_info": spider_data.get('app_info', {}),
                "country": spider_data.get('country'),
                "platform": platform
            }
            
            # æ·»åŠ çˆ¬è™«å…ƒæ•°æ®
            if metadata:
                platform_metadata.update(metadata)
            
            # åˆ›å»ºUserFeedbackæ–‡æ¡£
            feedback_doc = UserFeedback(
                content=content,
                original_content=content,
                source=source,
                source_platform=spider_data.get('source_platform', platform),
                original_id=spider_data.get('id', spider_data.get('review_id')),
                url=spider_data.get('url'),
                feedback_time=feedback_time,
                crawled_at=datetime.now(),
                user_id=spider_data.get('user_id', spider_data.get('author')),
                platform_metadata=platform_metadata,
                needs_llm_analysis=True,
                # å…¼å®¹æ€§å­—æ®µ
                original_text=content,
                processed_text=content
            )
            
            return feedback_doc
            
        except Exception as e:
            self.logger.error(f"è½¬æ¢çˆ¬è™«æ•°æ®å¤±è´¥: {e}")
            return None
    
    async def _convert_raw_data_to_feedback(self, 
                                          raw_data: Dict[str, Any], 
                                          source_type: str,
                                          metadata: Dict[str, Any] = None) -> Optional['UserFeedback']:
        """å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºUserFeedbackæ–‡æ¡£"""
        from ...models.database import UserFeedback, FeedbackSource
        
        try:
            # ä½¿ç”¨é€‚é…å™¨è½¬æ¢æ•°æ®
            feedback_data = self.transform_data(raw_data)
            if not feedback_data:
                return None
            
            # è½¬æ¢ä¸ºUserFeedbackæ–‡æ¡£
            feedback_doc = UserFeedback(
                content=feedback_data.content,
                original_content=feedback_data.content,
                source=FeedbackSource.INTERNAL,  # é»˜è®¤ä¸ºå†…éƒ¨æ•°æ®
                source_platform="internal",
                feedback_time=feedback_data.created_at,
                crawled_at=datetime.now(),
                user_id=str(feedback_data.user_info.user_id) if feedback_data.user_info else None,
                platform_metadata=metadata or {},
                # å…¼å®¹æ€§å­—æ®µ
                original_text=feedback_data.content,
                processed_text=feedback_data.content
            )
            
            return feedback_doc
            
        except Exception as e:
            self.logger.error(f"è½¬æ¢åŸå§‹æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _parse_spider_time(self, time_str: Any) -> Optional['datetime']:
        """è§£æçˆ¬è™«æ—¶é—´å­—ç¬¦ä¸²"""
        if not time_str:
            return None
        
        if isinstance(time_str, datetime):
            return time_str
        
        try:
            # å¸¸è§çš„æ—¶é—´æ ¼å¼
            formats = [
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%dT%H:%M:%S",
                "%Y-%m-%dT%H:%M:%S.%f",
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y/%m/%d %H:%M:%S",
                "%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S",
                "%Y-%m-%d"
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(str(time_str), fmt)
                except ValueError:
                    continue
            
            # å°è¯•è‡ªåŠ¨è§£æ
            import dateutil.parser
            return dateutil.parser.parse(str(time_str))
            
        except Exception as e:
            self.logger.warning(f"æ—¶é—´è§£æå¤±è´¥: {time_str}, {e}")
            return datetime.now()

    def get_supported_sources(self) -> List[DataSourceType]:
        """è·å–æ”¯æŒçš„æ•°æ®æºåˆ—è¡¨"""
        return list(self.adapters.keys())

# å…¨å±€é€‚é…å™¨æ³¨å†Œè¡¨
adapter_registry = DataAdapterRegistry()

def get_adapter_registry() -> DataAdapterRegistry:
    """è·å–é€‚é…å™¨æ³¨å†Œè¡¨å®ä¾‹"""
    return adapter_registry

def get_adapter_manager() -> DataAdapterRegistry:
    """è·å–é€‚é…å™¨ç®¡ç†å™¨å®ä¾‹ï¼ˆåˆ«åï¼‰"""
    return adapter_registry 